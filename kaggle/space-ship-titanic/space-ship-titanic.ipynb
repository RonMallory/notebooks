{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space Ship Titanic Kaggle Competition\n",
    "\n",
    "\n",
    "1. imports\n",
    "2. modules\n",
    "3. load data\n",
    "4. explore data\n",
    "5. preprocess data\n",
    "6. train model\n",
    "7. evaluate model\n",
    "8. write submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-13T22:32:16.024611Z",
     "iopub.status.busy": "2023-09-13T22:32:16.024236Z",
     "iopub.status.idle": "2023-09-13T22:32:16.033412Z",
     "shell.execute_reply": "2023-09-13T22:32:16.032641Z",
     "shell.execute_reply.started": "2023-09-13T22:32:16.024584Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 14:00:27.535739: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/var/folders/5h/tv_fm91j4f51f36xf151mwqr0000gp/T/ipykernel_93127/3106941359.py:20: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "# Standard Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# TensorFlow and Keras\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers, layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "import keras_tuner\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Typing\n",
    "from typing import Tuple, Dict,List\n",
    "from numpy import ndarray\n",
    "from pandas import DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill String Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_string_col(df: DataFrame, cols: List[str], default: str = 'Unknown') -> DataFrame:\n",
    "    for col in cols:\n",
    "        df[col] = df[col].fillna(default)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Most Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_most_common(df: DataFrame, cols: list) -> DataFrame:\n",
    "    for col in cols:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Average Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_average_round(df: DataFrame, cols: list) -> DataFrame:\n",
    "    for col in cols:\n",
    "        df[col] = df[col].fillna(round(df[col].mean()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data on Char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_on_char(df: DataFrame, col: str, split_on_char: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Splits a DataFrame column into multiple columns based on a character.\n",
    "    Leaves NaN values unchanged.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): Input DataFrame\n",
    "        col (str): Column name to split\n",
    "        split_on_char (str): Character to split on\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with new columns\n",
    "    \"\"\"\n",
    "    # Split the column\n",
    "    split_cols = df[col].str.split(split_on_char, expand=True)\n",
    "    split_cols.columns = [f\"{col}_{i+1}\" for i in range(split_cols.shape[1])]\n",
    "\n",
    "    # Drop the original column and concatenate the new columns\n",
    "    df = pd.concat([df.drop(columns=[col]), split_cols], axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Transported to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_transported_to_binary(df: DataFrame) -> DataFrame:\n",
    "    if \"Transported\" in df.columns:\n",
    "        df[\"Transported\"] = df[\"Transported\"].apply(lambda x: 1 if x == \"True\" else 0)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downcast DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dataframe(df):\n",
    "    \"\"\"\n",
    "    Downcast the columns of a Pandas DataFrame to the most efficient data types.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with downcasted columns\n",
    "    \"\"\"\n",
    "    df_downcasted = df.copy()\n",
    "    \n",
    "    # Downcast int and float types\n",
    "    for col in df_downcasted.select_dtypes(include=['int64', 'float64']).columns:\n",
    "        if pd.api.types.is_integer_dtype(df_downcasted[col]):\n",
    "            df_downcasted[col] = pd.to_numeric(df_downcasted[col], downcast='integer')\n",
    "        elif pd.api.types.is_float_dtype(df_downcasted[col]):\n",
    "            df_downcasted[col] = pd.to_numeric(df_downcasted[col], downcast='float')\n",
    "    \n",
    "    # Downcast object types to category if unique values are less than 50% of total values\n",
    "    for col in df_downcasted.select_dtypes(include=['object']).columns:\n",
    "        num_unique_values = len(df_downcasted[col].unique())\n",
    "        num_total_values = len(df_downcasted[col])\n",
    "        if num_unique_values / num_total_values < 0.5:\n",
    "            df_downcasted[col] = df_downcasted[col].astype('category')\n",
    "            \n",
    "    return df_downcasted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(df: DataFrame) -> Tuple[DataFrame, Dict[str, LabelEncoder]]:\n",
    "    label_encoders = {}\n",
    "    le = LabelEncoder()\n",
    "    categorical_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    return df, label_encoders\n",
    "\n",
    "def label_encode_2(df: DataFrame, cols: List[str]) -> Tuple[DataFrame, Dict[str, LabelEncoder]]:\n",
    "    label_encoders = {}\n",
    "    le = LabelEncoder()\n",
    "    for col in cols:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    return df, label_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df: DataFrame, cols: List[str]) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Perform one-hot encoding on the specified columns of a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Pandas DataFrame\n",
    "    - columns_to_encode: list of column names to one-hot encode\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with one-hot encoded columns\n",
    "    \"\"\"\n",
    "    # Perform one-hot encoding\n",
    "    df_encoded = pd.get_dummies(df, columns=cols, drop_first=False)\n",
    "    \n",
    "    return df_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_data(df: DataFrame) -> (DataFrame, DataFrame):\n",
    "    df_no_missing = df.dropna()\n",
    "    df_with_missing = df.loc[df.isna().any(axis=1)]\n",
    "    return df_no_missing, df_with_missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(\n",
    "    df: DataFrame, target_col: str = None\n",
    ") -> (DataFrame, StandardScaler):\n",
    "    \"\"\"\n",
    "    Scales the features of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to scale.\n",
    "        target_col (str): The target column to exclude from scaling.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The scaled DataFrame.\n",
    "        StandardScaler: The scaler used for scaling.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Separate target if it exists\n",
    "    if target_col and target_col in df.columns:\n",
    "        target = df[target_col]\n",
    "        features = df.drop(columns=[target_col])\n",
    "    else:\n",
    "        features = df\n",
    "\n",
    "    # Scale features\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    # Combine features and target back into a single DataFrame\n",
    "    if target_col and target_col in df.columns:\n",
    "        df_scaled = DataFrame(features_scaled, columns=features.columns, index=df.index)\n",
    "        df_scaled[target_col] = target\n",
    "    else:\n",
    "        df_scaled = DataFrame(features_scaled, columns=features.columns, index=df.index)\n",
    "\n",
    "    return df_scaled, scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(df_no_missing_scaled: DataFrame) -> Model:\n",
    "    input_layer = Input(shape=(df_no_missing_scaled.shape[1],))\n",
    "    encoder = Dense(128, activation=\"relu\")(input_layer)\n",
    "    encoder = Dense(64, activation=\"relu\")(encoder)\n",
    "    latent_space = Dense(32, activation=\"relu\")(encoder)\n",
    "    decoder = Dense(64, activation=\"relu\")(latent_space)\n",
    "    decoder = Dense(128, activation=\"relu\")(decoder)\n",
    "    output_layer = Dense(df_no_missing_scaled.shape[1], activation=\"linear\")(decoder)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    autoencoder.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    autoencoder.fit(\n",
    "        df_no_missing_scaled, df_no_missing_scaled, epochs=50, batch_size=128, verbose=0\n",
    "    )\n",
    "    return autoencoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(\n",
    "    df_with_missing: DataFrame, autoencoder: Model, scaler: StandardScaler\n",
    ") -> DataFrame:\n",
    "    # Scale the feature set with missing values\n",
    "    df_with_missing_scaled = scaler.transform(df_with_missing.fillna(0))\n",
    "\n",
    "    # Use the autoencoder to predict the missing values\n",
    "    imputed_values_scaled = autoencoder.predict(df_with_missing_scaled)\n",
    "\n",
    "    # Inverse transform to get the original feature values\n",
    "    imputed_values = scaler.inverse_transform(imputed_values_scaled)\n",
    "\n",
    "    # Replace the missing values in the original DataFrame\n",
    "    df_imputed = df_with_missing.copy()\n",
    "    is_null = df_with_missing.isna()\n",
    "    for i in range(df_with_missing.shape[0]):\n",
    "        for j in range(df_with_missing.shape[1]):\n",
    "            if is_null.iloc[i, j]:\n",
    "                df_imputed.iloc[i, j] = imputed_values[i, j]\n",
    "\n",
    "    return df_imputed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def preprocess(\n",
    "    df: DataFrame, target_col: str = \"Transported\"\n",
    ") -> Tuple[DataFrame, Dict[str, LabelEncoder]]:\n",
    "    \n",
    "    # Handle missing names\n",
    "    df = fill_string_col(df, ['Name'], 'Unknown')\n",
    "\n",
    "\n",
    "    # Split cabin column\n",
    "    df = split_data_on_char(df, \"Cabin\", \"/\")\n",
    "\n",
    "    # fill mode\n",
    "    mode_fill_cols = ['HomePlanet', 'CryoSleep', 'Destination','VIP', 'Cabin_1','Cabin_2','Cabin_3']\n",
    "    df = fill_most_common(df, mode_fill_cols)\n",
    "\n",
    "    # fill average\n",
    "    fill_average_cols = ['Age', 'RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']\n",
    "    df = fill_average_round(df, fill_average_cols)\n",
    "\n",
    "    # Label Encode\n",
    "    df, label_encoders = label_encode_2(df, ['Destination','HomePlanet','Name','Cabin_1','Cabin_3'])\n",
    "\n",
    "    # One-Hot Encode\n",
    "    df = one_hot_encode(df, ['Destination','HomePlanet','Cabin_3'])\n",
    "    # data type mapping\n",
    "    mapping = {\n",
    "        \"PassengerId\": \"category\",\n",
    "        \"CryoSleep\": \"int8\",\n",
    "        \"Age\": \"int16\",\n",
    "        \"VIP\": \"int8\",\n",
    "        \"RoomService\": \"int16\",\n",
    "        \"FoodCourt\": \"int16\",\n",
    "        \"ShoppingMall\": \"int16\",\n",
    "        \"Spa\": \"int16\",\n",
    "        \"VRDeck\": \"int16\",\n",
    "        \"Name\": \"int16\",\n",
    "        \"Cabin_1\": \"int8\",\n",
    "        \"Cabin_2\": \"int16\",\n",
    "        \"Destination_0\": \"int8\",\n",
    "        \"Destination_1\": \"int8\",\n",
    "        \"Destination_2\": \"int8\",\n",
    "        \"HomePlanet_0\": \"int8\",\n",
    "        \"HomePlanet_1\": \"int8\",\n",
    "        \"HomePlanet_2\": \"int8\",\n",
    "        \"Cabin_3_0\": \"int8\",\n",
    "        \"Cabin_3_1\": \"int8\",\n",
    "    }\n",
    "\n",
    "    df = df.astype(mapping)\n",
    "\n",
    "    # Downcast\n",
    "    df = downcast_dataframe(df)\n",
    "\n",
    "    # Separate out the target column\n",
    "    if target_col in df.columns:\n",
    "        target = df[target_col]\n",
    "        features = df.drop(columns=[target_col])\n",
    "    else:\n",
    "        features = df\n",
    "\n",
    "    # # If the target exists, add it back\n",
    "    if target_col in df.columns:\n",
    "        features[target_col] = target\n",
    "\n",
    "    return features, label_encoders\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history_with_metrics(history, y_true, y_pred_proba):\n",
    "    \"\"\"\n",
    "    Plots the training and validation loss, accuracy, and provides interpretations notes.\n",
    "    Also calculates F1 Score and ROC AUC Score.\n",
    "\n",
    "    Parameters:\n",
    "        history (History): History object returned from model training.\n",
    "        y_true (array-like): True labels for the validation set.\n",
    "        y_pred_proba (array-like): Predicted probabilities for the positive class.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract training and validation loss\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    # Extract training and validation accuracy if it exists\n",
    "    accuracy = history.history.get(\"accuracy\")\n",
    "    val_accuracy = history.history.get(\"val_accuracy\")\n",
    "\n",
    "    # Create figure and axis\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Plot loss\n",
    "    color = \"tab:red\"\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\", color=color)\n",
    "    ax1.plot(loss, label=\"Train Loss\", color=color)\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "    # Create another y-axis for the accuracies\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    color = \"tab:blue\"\n",
    "    ax2.set_ylabel(\"Accuracy\", color=color)\n",
    "\n",
    "    # Plot accuracy if it exists\n",
    "    if accuracy and val_accuracy:\n",
    "        ax2.plot(accuracy, label=\"Train Acc\", color=color)\n",
    "        ax2.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "    # Plot validation data if it exists\n",
    "    if val_loss:\n",
    "        ax1.plot(val_loss, label=\"Val Loss\", color=\"tab:orange\")\n",
    "\n",
    "    if val_accuracy:\n",
    "        ax2.plot(val_accuracy, label=\"Val Acc\", color=\"tab:cyan\")\n",
    "\n",
    "    # Add legends\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    lines = lines1 + lines2\n",
    "    labels = labels1 + labels2\n",
    "    ax1.legend(lines, labels, loc=0)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Additional Metrics\n",
    "    y_pred = np.round(y_pred_proba)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    print(f\"\\nAdditional Metrics:\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"ROC AUC Score: {roc_auc}\")\n",
    "    print()\n",
    "\n",
    "    # Interpretation\n",
    "    print(\"Interpreting the Graph:\")\n",
    "    print(\n",
    "        \"- F1 Score: 2 * (precision * recall) / (precision + recall).  The F1 Score is the harmonic mean of precision and recall. Precision measures how many of the items identified as positive are actually positive, while recall measures how many of the actual positive items are identified correctly.\"\n",
    "    )\n",
    "    print(\n",
    "        \"- ROC AUC Score: The Area Under the Receiver Operating Characteristic Curve (ROC AUC) is a measure of how well a model can distinguish between classes. An ROC AUC of 0.5 means the model is randomly guessing, while an ROC AUC of 1.0 means the model is perfectly distinguishing between positive and negative classes.\"\n",
    "    )\n",
    "    print(\"- A lower 'Loss' means the model is performing better.\")\n",
    "    print(\n",
    "        \"- 'Train Loss' and 'Val Loss' should follow a similar trend. If 'Val Loss' starts increasing while 'Train Loss' continues decreasing, it's likely the model is overfitting.\"\n",
    "    )\n",
    "    print(\n",
    "        \"- Higher 'Accuracy' is generally better, but be cautious if accuracy is very high as it might be a sign of overfitting or a too-simple model.\"\n",
    "    )\n",
    "    print(\n",
    "        \"- 'Train Acc' and 'Val Acc' should also follow similar trends. If 'Val Acc' plateaus or starts decreasing, consider stopping the training or modifying the model.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Submission Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_dataframe(\n",
    "    y_test_pred: ndarray, passenger_ids: ndarray, threshold: float = 0.5\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Create a submission DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        y_test_pred (np.ndarray): Model predictions.\n",
    "        passenger_ids (np.ndarray): IDs corresponding to the test set.\n",
    "        threshold (float): Threshold for classifying as 1.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Submission DataFrame.\n",
    "    \"\"\"\n",
    "    # Convert probabilities to binary outputs\n",
    "    y_test_pred_binary = (y_test_pred > threshold).astype(int).flatten()\n",
    "\n",
    "    # Create a DataFrame for submission\n",
    "    submission_df = DataFrame(\n",
    "        {\"PassengerId\": passenger_ids, \"Transported\": y_test_pred_binary}\n",
    "    )\n",
    "\n",
    "    return submission_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test and training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running notebook in local environment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Try to load Kaggle dataset\n",
    "    train_data_path = \"/kaggle/input/spaceship-titanic/train.csv\"\n",
    "    test_data_path = \"/kaggle/input/spaceship-titanic/test.csv\"\n",
    "\n",
    "    train = pd.read_csv(train_data_path)\n",
    "    test = pd.read_csv(test_data_path)\n",
    "    print(\"Running notebook in Kaggle environment\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    # Fall back to local dataset\n",
    "    train_data_path = \"./data/spaceship-titanic/train.csv\"\n",
    "    test_data_path = \"./data/spaceship-titanic/test.csv\"\n",
    "    print(\"Running notebook in local environment\")\n",
    "\n",
    "\n",
    "train = pd.read_csv(train_data_path)\n",
    "test = pd.read_csv(test_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T22:32:16.073450Z",
     "iopub.status.busy": "2023-09-13T22:32:16.072587Z",
     "iopub.status.idle": "2023-09-13T22:32:16.078580Z",
     "shell.execute_reply": "2023-09-13T22:32:16.077310Z",
     "shell.execute_reply.started": "2023-09-13T22:32:16.073422Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:(8693, 14)\n",
      "test shape:(4277, 13)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train shape:{train.shape}\")\n",
    "print(f\"test shape:{test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T22:32:16.098075Z",
     "iopub.status.busy": "2023-09-13T22:32:16.097728Z",
     "iopub.status.idle": "2023-09-13T22:32:16.117366Z",
     "shell.execute_reply": "2023-09-13T22:32:16.116227Z",
     "shell.execute_reply.started": "2023-09-13T22:32:16.098046Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"train head:\")\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test head:   PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
      "0     0013_01      Earth      True  G/3/S  TRAPPIST-1e  27.0  False   \n",
      "1     0018_01      Earth     False  F/4/S  TRAPPIST-1e  19.0  False   \n",
      "2     0019_01     Europa      True  C/0/S  55 Cancri e  31.0  False   \n",
      "3     0021_01     Europa     False  C/1/S  TRAPPIST-1e  38.0  False   \n",
      "4     0023_01      Earth     False  F/5/S  TRAPPIST-1e  20.0  False   \n",
      "\n",
      "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \n",
      "0          0.0        0.0           0.0     0.0     0.0   Nelly Carsoning  \n",
      "1          0.0        9.0           0.0  2823.0     0.0    Lerome Peckers  \n",
      "2          0.0        0.0           0.0     0.0     0.0   Sabih Unhearfus  \n",
      "3          0.0     6652.0           0.0   181.0   585.0  Meratz Caltilter  \n",
      "4         10.0        0.0         635.0     0.0     0.0   Brence Harperez  \n"
     ]
    }
   ],
   "source": [
    "print(f\"test head: {test.head()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T22:32:16.119801Z",
     "iopub.status.busy": "2023-09-13T22:32:16.119476Z",
     "iopub.status.idle": "2023-09-13T22:32:16.138274Z",
     "shell.execute_reply": "2023-09-13T22:32:16.137393Z",
     "shell.execute_reply.started": "2023-09-13T22:32:16.119772Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n",
      "train info: None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4277 entries, 0 to 4276\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   4277 non-null   object \n",
      " 1   HomePlanet    4190 non-null   object \n",
      " 2   CryoSleep     4184 non-null   object \n",
      " 3   Cabin         4177 non-null   object \n",
      " 4   Destination   4185 non-null   object \n",
      " 5   Age           4186 non-null   float64\n",
      " 6   VIP           4184 non-null   object \n",
      " 7   RoomService   4195 non-null   float64\n",
      " 8   FoodCourt     4171 non-null   float64\n",
      " 9   ShoppingMall  4179 non-null   float64\n",
      " 10  Spa           4176 non-null   float64\n",
      " 11  VRDeck        4197 non-null   float64\n",
      " 12  Name          4183 non-null   object \n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 434.5+ KB\n",
      "test info: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"train info: {train.info()}\")\n",
    "print(f\"test info: {test.info()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T22:32:16.166401Z",
     "iopub.status.busy": "2023-09-13T22:32:16.165554Z",
     "iopub.status.idle": "2023-09-13T22:32:16.191921Z",
     "shell.execute_reply": "2023-09-13T22:32:16.190891Z",
     "shell.execute_reply.started": "2023-09-13T22:32:16.166364Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train describe:                Age   RoomService     FoodCourt  ShoppingMall           Spa  \\\n",
      "count  8514.000000   8512.000000   8510.000000   8485.000000   8510.000000   \n",
      "mean     28.827930    224.687617    458.077203    173.729169    311.138778   \n",
      "std      14.489021    666.717663   1611.489240    604.696458   1136.705535   \n",
      "min       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%      19.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%      27.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%      38.000000     47.000000     76.000000     27.000000     59.000000   \n",
      "max      79.000000  14327.000000  29813.000000  23492.000000  22408.000000   \n",
      "\n",
      "             VRDeck  \n",
      "count   8505.000000  \n",
      "mean     304.854791  \n",
      "std     1145.717189  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%       46.000000  \n",
      "max    24133.000000  \n",
      "test describe:                Age   RoomService     FoodCourt  ShoppingMall           Spa  \\\n",
      "count  4186.000000   4195.000000   4171.000000   4179.000000   4176.000000   \n",
      "mean     28.658146    219.266269    439.484296    177.295525    303.052443   \n",
      "std      14.179072    607.011289   1527.663045    560.821123   1117.186015   \n",
      "min       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%      19.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%      26.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%      37.000000     53.000000     78.000000     33.000000     50.000000   \n",
      "max      79.000000  11567.000000  25273.000000   8292.000000  19844.000000   \n",
      "\n",
      "             VRDeck  \n",
      "count   4197.000000  \n",
      "mean     310.710031  \n",
      "std     1246.994742  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%       36.000000  \n",
      "max    22272.000000  \n"
     ]
    }
   ],
   "source": [
    "print(f\"train describe: {train.describe()}\")\n",
    "print(f\"test describe: {test.describe()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T22:32:16.194475Z",
     "iopub.status.busy": "2023-09-13T22:32:16.194100Z",
     "iopub.status.idle": "2023-09-13T22:32:16.212826Z",
     "shell.execute_reply": "2023-09-13T22:32:16.211360Z",
     "shell.execute_reply.started": "2023-09-13T22:32:16.194445Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train nunique: PassengerId     8693\n",
      "HomePlanet         3\n",
      "CryoSleep          2\n",
      "Cabin           6560\n",
      "Destination        3\n",
      "Age               80\n",
      "VIP                2\n",
      "RoomService     1273\n",
      "FoodCourt       1507\n",
      "ShoppingMall    1115\n",
      "Spa             1327\n",
      "VRDeck          1306\n",
      "Name            8473\n",
      "Transported        2\n",
      "dtype: int64\n",
      "test nunique: PassengerId     4277\n",
      "HomePlanet         3\n",
      "CryoSleep          2\n",
      "Cabin           3265\n",
      "Destination        3\n",
      "Age               79\n",
      "VIP                2\n",
      "RoomService      842\n",
      "FoodCourt        902\n",
      "ShoppingMall     715\n",
      "Spa              833\n",
      "VRDeck           796\n",
      "Name            4176\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"train nunique: {train.nunique()}\")\n",
    "print(f\"test nunique: {test.nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T22:32:16.214783Z",
     "iopub.status.busy": "2023-09-13T22:32:16.214196Z",
     "iopub.status.idle": "2023-09-13T22:32:16.226867Z",
     "shell.execute_reply": "2023-09-13T22:32:16.225377Z",
     "shell.execute_reply.started": "2023-09-13T22:32:16.214754Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train isnull: PassengerId       0\n",
      "HomePlanet      201\n",
      "CryoSleep       217\n",
      "Cabin           199\n",
      "Destination     182\n",
      "Age             179\n",
      "VIP             203\n",
      "RoomService     181\n",
      "FoodCourt       183\n",
      "ShoppingMall    208\n",
      "Spa             183\n",
      "VRDeck          188\n",
      "Name            200\n",
      "Transported       0\n",
      "dtype: int64\n",
      "test isnull: PassengerId       0\n",
      "HomePlanet       87\n",
      "CryoSleep        93\n",
      "Cabin           100\n",
      "Destination      92\n",
      "Age              91\n",
      "VIP              93\n",
      "RoomService      82\n",
      "FoodCourt       106\n",
      "ShoppingMall     98\n",
      "Spa             101\n",
      "VRDeck           80\n",
      "Name             94\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"train isnull: {train.isnull().sum()}\")\n",
    "print(f\"test isnull: {test.isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train nulls: PassengerId       0\n",
      "HomePlanet      201\n",
      "CryoSleep       217\n",
      "Cabin           199\n",
      "Destination     182\n",
      "Age             179\n",
      "VIP             203\n",
      "RoomService     181\n",
      "FoodCourt       183\n",
      "ShoppingMall    208\n",
      "Spa             183\n",
      "VRDeck          188\n",
      "Name            200\n",
      "Transported       0\n",
      "dtype: int64\n",
      "test nulls: PassengerId       0\n",
      "HomePlanet       87\n",
      "CryoSleep        93\n",
      "Cabin           100\n",
      "Destination      92\n",
      "Age              91\n",
      "VIP              93\n",
      "RoomService      82\n",
      "FoodCourt       106\n",
      "ShoppingMall     98\n",
      "Spa             101\n",
      "VRDeck           80\n",
      "Name             94\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"train nulls: {train.isnull().sum()}\")\n",
    "print(f\"test nulls: {test.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train nulls: PassengerId     0.000000\n",
      "HomePlanet      0.023122\n",
      "CryoSleep       0.024963\n",
      "Cabin           0.022892\n",
      "Destination     0.020936\n",
      "Age             0.020591\n",
      "VIP             0.023352\n",
      "RoomService     0.020821\n",
      "FoodCourt       0.021051\n",
      "ShoppingMall    0.023927\n",
      "Spa             0.021051\n",
      "VRDeck          0.021627\n",
      "Name            0.023007\n",
      "Transported     0.000000\n",
      "dtype: float64\n",
      "test nulls: PassengerId     0.000000\n",
      "HomePlanet      0.020341\n",
      "CryoSleep       0.021744\n",
      "Cabin           0.023381\n",
      "Destination     0.021510\n",
      "Age             0.021277\n",
      "VIP             0.021744\n",
      "RoomService     0.019172\n",
      "FoodCourt       0.024784\n",
      "ShoppingMall    0.022913\n",
      "Spa             0.023615\n",
      "VRDeck          0.018705\n",
      "Name            0.021978\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"train nulls: {train.isnull().sum() / train.shape[0]}\")\n",
    "print(f\"test nulls: {test.isnull().sum() / test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP', 'Name']\n"
     ]
    }
   ],
   "source": [
    "# get all categorical columns\n",
    "train_categorical_cols = train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "print(train_categorical_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Columns Strategy\n",
    "\n",
    "### PassengerId\n",
    "\n",
    "- Unique Identifier\n",
    "- No encoding\n",
    "\n",
    "### HomePlanet\n",
    "\n",
    "- fill missing with mode\n",
    "- One-Hot Encode\n",
    "\n",
    "### CryoSleep\n",
    "\n",
    "- Fill missing with mode\n",
    "- Binary\n",
    "\n",
    "### Cabin\n",
    "\n",
    "Cabin seems like an interesting feature.  There is three fields in Cabin 'B/0/P' 'char'/'int8'/'char'\n",
    "\n",
    "- Split data on '/'\n",
    "  - Cabin_1 = 'char'\n",
    "  - Cabin_2 = 'int8'\n",
    "  - Cabin_3 = 'char'\n",
    "- Fill NaN\n",
    "  - Cabin_1 = Most Frequent\n",
    "  - Cabin_2 = Median\n",
    "  - Cabin_3 = Most Frequent\n",
    "- Encode\n",
    "  - Need to see the distributions of of the newly created features.\n",
    "\n",
    "### Destination\n",
    "\n",
    "- Fill missing with mode\n",
    "- Label Encode\n",
    "\n",
    "### VIP\n",
    "\n",
    "- Fill missing with median\n",
    "- Binary\n",
    "\n",
    "### Name\n",
    "- fill missing with 'Unknown'\n",
    "- Label Encode\n",
    "- Suspect column will not be relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "mode_fill_cols = ['HomePlanet', 'CryoSleep', 'Destination','VIP']\n",
    "train = fill_most_common(train, mode_fill_cols)\n",
    "test = fill_most_common(test, mode_fill_cols)\n",
    "\n",
    "train = fill_string_col(train, ['Name'])\n",
    "test = fill_string_col(test, ['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "HomePlanet        0\n",
       "CryoSleep         0\n",
       "Cabin           199\n",
       "Destination       0\n",
       "Age             179\n",
       "VIP               0\n",
       "RoomService     181\n",
       "FoodCourt       183\n",
       "ShoppingMall    208\n",
       "Spa             183\n",
       "VRDeck          188\n",
       "Name              0\n",
       "Transported       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split Cabin\n",
    "# train = split_data_on_char(train, \"Cabin\", \"/\")\n",
    "# test = split_data_on_char(test, \"Cabin\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet  CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa      False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth      False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa      False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa      False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth      False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet  CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "8688     9276_01     Europa      False    A/98/P    55 Cancri e  41.0   True   \n",
       "8689     9278_01      Earth       True  G/1499/S  PSO J318.5-22  18.0  False   \n",
       "8690     9279_01      Earth      False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
       "8691     9280_01     Europa      False   E/608/S    55 Cancri e  32.0  False   \n",
       "8692     9280_02     Europa      False   E/608/S    TRAPPIST-1e  44.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
       "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
       "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
       "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
       "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
       "\n",
       "      Transported  \n",
       "8688        False  \n",
       "8689        False  \n",
       "8690         True  \n",
       "8691        False  \n",
       "8692         True  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId     8693\n",
       "HomePlanet         3\n",
       "CryoSleep          2\n",
       "Cabin           6560\n",
       "Destination        3\n",
       "Age               80\n",
       "VIP                2\n",
       "RoomService     1273\n",
       "FoodCourt       1507\n",
       "ShoppingMall    1115\n",
       "Spa             1327\n",
       "VRDeck          1306\n",
       "Name            8474\n",
       "Transported        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train nulls: PassengerId     0.000000\n",
      "HomePlanet      0.000000\n",
      "CryoSleep       0.000000\n",
      "Cabin           0.022892\n",
      "Destination     0.000000\n",
      "Age             0.020591\n",
      "VIP             0.000000\n",
      "RoomService     0.020821\n",
      "FoodCourt       0.021051\n",
      "ShoppingMall    0.023927\n",
      "Spa             0.021051\n",
      "VRDeck          0.021627\n",
      "Name            0.000000\n",
      "Transported     0.000000\n",
      "dtype: float64\n",
      "test nulls: PassengerId     0.000000\n",
      "HomePlanet      0.000000\n",
      "CryoSleep       0.000000\n",
      "Cabin           0.023381\n",
      "Destination     0.000000\n",
      "Age             0.021277\n",
      "VIP             0.000000\n",
      "RoomService     0.019172\n",
      "FoodCourt       0.024784\n",
      "ShoppingMall    0.022913\n",
      "Spa             0.023615\n",
      "VRDeck          0.018705\n",
      "Name            0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"train nulls: {train.isnull().sum() / train.shape[0]}\")\n",
    "print(f\"test nulls: {test.isnull().sum() / test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin_1\n",
    "\n",
    "- fill with mode\n",
    "- One-Hot Encode\n",
    "\n",
    "### Cabin_2\n",
    "\n",
    "- fill with mode\n",
    "- int64 maybe smaller depending on width\n",
    "\n",
    "### Cabin_3\n",
    "\n",
    "- fill with mode\n",
    "- label encode\n",
    "- int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all numerical columns\n",
    "# train_numerical_cols = train.select_dtypes(\n",
    "#     include=[\"int64\", \"float64\"]\n",
    "# ).columns.tolist()\n",
    "# print(train_numerical_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Columns Strategy\n",
    "\n",
    "### Age\n",
    "\n",
    "- Fill with average whole number\n",
    "- float32\n",
    "\n",
    "### RoomService\n",
    "\n",
    "- Fill with average whole number\n",
    "- float64\n",
    "\n",
    "\n",
    "### FoodCourt\n",
    "\n",
    "- Fill with average whole number\n",
    "- float64\n",
    "\n",
    "\n",
    "### ShoppingMall\n",
    "\n",
    "- Fill with average whole number\n",
    "- float64\n",
    "\n",
    "### Spa\n",
    "\n",
    "- Fill with average whole number\n",
    "- float64\n",
    "\n",
    "### VRDeck\n",
    "\n",
    "- Fill with average whole number\n",
    "- float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill_average_cols = ['Age', 'RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']\n",
    "\n",
    "# train = fill_average_round(train, fill_average_cols)\n",
    "# test = fill_average_round(test, fill_average_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcess Test and Training Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocess the data to fill missing values\n",
    "train_processed, train_label_encoder = preprocess(train)\n",
    "test_processed, test_label_encoder = preprocess(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Cabin_1</th>\n",
       "      <th>Cabin_2</th>\n",
       "      <th>Destination_0</th>\n",
       "      <th>Destination_1</th>\n",
       "      <th>Destination_2</th>\n",
       "      <th>HomePlanet_0</th>\n",
       "      <th>HomePlanet_1</th>\n",
       "      <th>HomePlanet_2</th>\n",
       "      <th>Cabin_3_0</th>\n",
       "      <th>Cabin_3_1</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5252</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>549</td>\n",
       "      <td>44</td>\n",
       "      <td>4502</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>3576</td>\n",
       "      <td>0</td>\n",
       "      <td>6715</td>\n",
       "      <td>49</td>\n",
       "      <td>457</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1283</td>\n",
       "      <td>371</td>\n",
       "      <td>3329</td>\n",
       "      <td>193</td>\n",
       "      <td>7149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>70</td>\n",
       "      <td>151</td>\n",
       "      <td>565</td>\n",
       "      <td>2</td>\n",
       "      <td>8320</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  CryoSleep  Age  VIP  RoomService  FoodCourt  ShoppingMall  \\\n",
       "0     0001_01          0   39    0            0          0             0   \n",
       "1     0002_01          0   24    0          109          9            25   \n",
       "2     0003_01          0   58    1           43       3576             0   \n",
       "3     0003_02          0   33    0            0       1283           371   \n",
       "4     0004_01          0   16    0          303         70           151   \n",
       "\n",
       "    Spa  VRDeck  Name  Cabin_1  Cabin_2  Destination_0  Destination_1  \\\n",
       "0     0       0  5252        1        0              0              0   \n",
       "1   549      44  4502        5        0              0              0   \n",
       "2  6715      49   457        0        0              0              0   \n",
       "3  3329     193  7149        0        0              0              0   \n",
       "4   565       2  8320        5        1              0              0   \n",
       "\n",
       "   Destination_2  HomePlanet_0  HomePlanet_1  HomePlanet_2  Cabin_3_0  \\\n",
       "0              1             0             1             0          1   \n",
       "1              1             1             0             0          0   \n",
       "2              1             0             1             0          0   \n",
       "3              1             0             1             0          0   \n",
       "4              1             1             0             0          0   \n",
       "\n",
       "   Cabin_3_1  Transported  \n",
       "0          0        False  \n",
       "1          1         True  \n",
       "2          1        False  \n",
       "3          1        False  \n",
       "4          1         True  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "train_processed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      category\n",
       "CryoSleep            int8\n",
       "Age                 int16\n",
       "VIP                  int8\n",
       "RoomService         int16\n",
       "FoodCourt           int16\n",
       "ShoppingMall        int16\n",
       "Spa                 int16\n",
       "VRDeck              int16\n",
       "Name                int16\n",
       "Cabin_1              int8\n",
       "Cabin_2             int16\n",
       "Destination_0        int8\n",
       "Destination_1        int8\n",
       "Destination_2        int8\n",
       "HomePlanet_0         int8\n",
       "HomePlanet_1         int8\n",
       "HomePlanet_2         int8\n",
       "Cabin_3_0            int8\n",
       "Cabin_3_1            int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed.shape\n",
    "test_processed.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call Backs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=6,\n",
    "    verbose=1,\n",
    "    mode='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features to include\n",
    "selected_features = [\n",
    "    \"CryoSleep\",\n",
    "    \"Age\",\n",
    "    \"RoomService\",\n",
    "    \"FoodCourt\",\n",
    "    \"ShoppingMall\",\n",
    "    \"VIP\",\n",
    "    \"Spa\",\n",
    "    \"VRDeck\",\n",
    "    \"Cabin_1\",\n",
    "    \"Cabin_2\",\n",
    "    \"Cabin_3_0\",\n",
    "    \"Cabin_3_1\",\n",
    "    \"Destination_0\",\n",
    "    \"Destination_1\",\n",
    "    \"Destination_2\",\n",
    "    \"HomePlanet_0\",\n",
    "    \"HomePlanet_1\",\n",
    "    \"HomePlanet_2\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split features and target variable from training data\n",
    "x_train_all = train_processed.drop(\"Transported\", axis=1)\n",
    "y_train = train_processed[\"Transported\"]\n",
    "\n",
    "# Filter the training data to keep only selected features\n",
    "x_train = x_train_all[selected_features]\n",
    "\n",
    "# Assuming test_processed contains all potential features\n",
    "x_test_all = test_processed\n",
    "\n",
    "# Keep only columns also present in the training set\n",
    "x_test = x_test_all[x_train.columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "x_train_scaled = x_train\n",
    "x_test_scaled = x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "    \n",
    "    def build(self, hp: Dict[str, float]) -> Model:\n",
    "        model = Sequential()\n",
    "        for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "            kwargs = {\n",
    "                \"units\": hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                \"activation\": hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            }\n",
    "            if i == 0:\n",
    "                kwargs[\"input_shape\"] = (self.input_shape,)\n",
    "            model.add(layers.Dense(**kwargs))\n",
    "\n",
    "        if hp.Boolean(\"dropout\"):\n",
    "            model.add(layers.Dropout(rate=0.25))\n",
    "\n",
    "        learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "\n",
    "        model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=learning_rate),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, x, y, **kwargs):\n",
    "        if hp.Boolean(\"normalize\"):\n",
    "            x = layers.Normalization()(x)\n",
    "        return model.fit(\n",
    "            x,\n",
    "            y,\n",
    "            # Tune whether to shuffle the data in each epoch.\n",
    "            shuffle=hp.Boolean(\"shuffle\"),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_shape = x_train_scaled.shape[1]  # Number of features in the dataset\n",
    "\n",
    "hp = keras_tuner.HyperParameters()\n",
    "hypermodel = MyHyperModel(input_shape=input_shape)\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel=hypermodel,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    overwrite=True,\n",
    "    directory=\"models\",\n",
    "    project_name=\"sst\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 05s]\n",
      "val_accuracy: 0.7341383894284567\n",
      "\n",
      "Best val_accuracy So Far: 0.7906842827796936\n",
      "Total elapsed time: 00h 00m 58s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 192)               3648      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 288)               55584     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 288)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59521 (232.50 KB)\n",
      "Trainable params: 59521 (232.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Results summary\n",
      "Results in models/sst\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 192\n",
      "activation: tanh\n",
      "dropout: True\n",
      "lr: 0.0006654334507308442\n",
      "units_1: 288\n",
      "normalize: True\n",
      "shuffle: False\n",
      "Score: 0.7906842827796936\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 448\n",
      "activation: tanh\n",
      "dropout: False\n",
      "lr: 0.00028065294118723584\n",
      "units_1: 32\n",
      "normalize: False\n",
      "shuffle: False\n",
      "Score: 0.7904926339785258\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 320\n",
      "activation: tanh\n",
      "dropout: False\n",
      "lr: 0.0008531941855305934\n",
      "units_1: 448\n",
      "normalize: True\n",
      "shuffle: False\n",
      "Score: 0.7841671506563822\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 384\n",
      "activation: relu\n",
      "dropout: False\n",
      "lr: 0.007163902356609689\n",
      "units_1: 64\n",
      "normalize: True\n",
      "shuffle: False\n",
      "Score: 0.7694077094395956\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 384\n",
      "activation: tanh\n",
      "dropout: False\n",
      "lr: 0.00020147723244454295\n",
      "units_1: 448\n",
      "normalize: True\n",
      "shuffle: True\n",
      "Score: 0.7609737515449524\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 480\n",
      "activation: relu\n",
      "dropout: False\n",
      "lr: 0.00041180555949411874\n",
      "units_1: 128\n",
      "normalize: True\n",
      "shuffle: False\n",
      "Score: 0.7594403028488159\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 192\n",
      "activation: relu\n",
      "dropout: False\n",
      "lr: 0.0010637278760861717\n",
      "units_1: 384\n",
      "normalize: True\n",
      "shuffle: False\n",
      "Score: 0.7341383894284567\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 96\n",
      "activation: relu\n",
      "dropout: False\n",
      "lr: 0.0007373196097809678\n",
      "units_1: 480\n",
      "normalize: True\n",
      "shuffle: False\n",
      "Score: 0.7312631607055664\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 416\n",
      "activation: relu\n",
      "dropout: False\n",
      "lr: 0.0006007157534818649\n",
      "units_1: 96\n",
      "normalize: False\n",
      "shuffle: True\n",
      "Score: 0.7253210544586182\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 128\n",
      "activation: tanh\n",
      "dropout: True\n",
      "lr: 0.0001358890865258992\n",
      "units_1: 512\n",
      "normalize: False\n",
      "shuffle: True\n",
      "Score: 0.6787425875663757\n",
      "Epoch 1/10\n",
      "544/544 [==============================] - 2s 2ms/step - loss: 0.5278 - accuracy: 0.7665\n",
      "Epoch 2/10\n",
      "544/544 [==============================] - 1s 2ms/step - loss: 0.5024 - accuracy: 0.7727\n",
      "Epoch 3/10\n",
      "544/544 [==============================] - 1s 2ms/step - loss: 0.4845 - accuracy: 0.7790\n",
      "Epoch 4/10\n",
      "544/544 [==============================] - 1s 2ms/step - loss: 0.4783 - accuracy: 0.7780\n",
      "Epoch 5/10\n",
      "544/544 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.7830\n",
      "Epoch 6/10\n",
      "544/544 [==============================] - 1s 2ms/step - loss: 0.4684 - accuracy: 0.7812\n",
      "Epoch 7/10\n",
      "544/544 [==============================] - 1s 2ms/step - loss: 0.4665 - accuracy: 0.7818\n",
      "Epoch 8/10\n",
      "544/544 [==============================] - 1s 2ms/step - loss: 0.4633 - accuracy: 0.7846\n",
      "Epoch 9/10\n",
      "544/544 [==============================] - 1s 2ms/step - loss: 0.4580 - accuracy: 0.7863\n",
      "Epoch 10/10\n",
      "544/544 [==============================] - 1s 2ms/step - loss: 0.4597 - accuracy: 0.7865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14a50b790>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir = \"logs/tune/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "tuner.search(x_train_scaled, y_train, epochs=2, validation_split=0.2, callbacks=[tensorboard_callback, early_stopping])\n",
    "\n",
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "\n",
    "# Build the model.\n",
    "best_model.build(input_shape=input_shape)\n",
    "best_model.summary()\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "# Get the top 2 hyperparameters.\n",
    "best_hps = tuner.get_best_hyperparameters(2)\n",
    "\n",
    "# Build the model with the best hp\n",
    "input_shape = x_train_scaled.shape[1]\n",
    "model = hypermodel.build(best_hps[0])\n",
    "\n",
    "\n",
    "# Fit with the entire dataset.\n",
    "# Update these lines to match your refactored variable names\n",
    "x_all = np.concatenate((x_train_scaled, x_train_scaled))  # Assuming x_val_scaled exists\n",
    "y_all = np.concatenate((y_train, y_train))  # Assuming y_val exists\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model.fit(x=x_all, y=y_all, epochs=10, callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 93337), started 0:04:02 ago. (Use '!kill 93337' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a4b9303742d72a0c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a4b9303742d72a0c\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/134 [======================>.......] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 1ms/step\n",
      "272/272 [==============================] - 0s 768us/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set (scaled)\n",
    "y_test_pred = model.predict(x_test_scaled)\n",
    "# Make predictions on the train set (scaled)\n",
    "y_train_pred = model.predict(x_train_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the submission DataFrame\n",
    "submission_df = create_submission_dataframe(y_test_pred, test[\"PassengerId\"])\n",
    "\n",
    "# Set Transported to boolean\n",
    "submission_df[\"Transported\"] = submission_df[\"Transported\"].apply(\n",
    "    lambda x: True if x == 1 else False\n",
    ")\n",
    "# To save the DataFrame as a CSV file\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
